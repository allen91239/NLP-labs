# -*- coding: utf-8 -*-
"""lab4-team_london_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1urEoeM7AgQelJIjqgT6kXrRX-Uu4ZWSB
"""

from google.colab import files
from collections import defaultdict
import csv
import re
import time
import pytz
from datetime import datetime, timezone
#uploaded = files.upload()

"""# Authenticate"""

import boto3
import pandas as pd

CREDENTIALS_FILE = 'credentials.csv'
credentials = pd.read_csv(CREDENTIALS_FILE).to_dict('records')[0]
aws_access_key_id = credentials['Access key ID']
aws_secret_access_key = credentials['Secret access key']

region_name = 'us-east-1'
endpoint_url = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'

# Uncomment this line to use in production
# endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'
 
client = boto3.client(
    'mturk',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    endpoint_url=endpoint_url,
    region_name=region_name
)

"""#Get  Balance"""

#print(client.get_account_balance())

"""#Create HIT Type"""

"""
one_minute = 60 # seconds
one_hour = 60 * one_minute
one_day = 24 * one_hour
#questions = open('./q.xml', mode='r').read()
#answers = open('./a.xml', mode='r').read()
"""
"""
qual_response = client.create_qualification_type(
                        Name='offensive test',
                        Keywords='test, qualification, tweet, offensive, boto',
                        Description='This is a test to make sure that you can accept offensive tweets',
                        QualificationTypeStatus='Active',
                        Test=questions,
                        AnswerKey=answers,
                        TestDurationInSeconds=300)

print(qual_response['QualificationType']['QualificationTypeId'])
qtype = qual_response['QualificationType']['QualificationTypeId']
"""
"""
#32X4OLFWW4UYZYT0ET6G5H3L9UETDG
hit_type_response = client.create_hit_type(
    AutoApprovalDelayInSeconds=60 * one_minute,
    AssignmentDurationInSeconds=30 * one_minute,
    Reward='0.50',
    Title='Short Tweet Emotions',
    Keywords='tweet,language,emotion,nctu,nlp,NCTU,NLP,TWEET,NCTU_Team_London',
    Description='Decide how a tweet feels (May include offensive content)',
    QualificationRequirements=[
        {
            'QualificationTypeId': '00000000000000000071', # see https://docs.aws.amazon.com/AWSMechTurk/latest/AWSMturkAPI/ApiReference_QualificationRequirementDataStructureArticle.html#ApiReference_QualificationType-IDs
            'Comparator': 'In',
            'LocaleValues': [
                {
                    'Country': 'TW'
                },
                {
                    'Country': 'US'
                },
            ],
            'RequiredToPreview': True,
            'ActionsGuarded': 'PreviewAndAccept'
        },{'QualificationTypeId':'32X4OLFWW4UYZYT0ET6G5H3L9UETDG',
                                   'Comparator': 'EqualTo',
                                   'IntegerValues':[1]},
    ]
)
hit_type_response1 = client.create_hit_type(
    AutoApprovalDelayInSeconds=60 * one_minute,
    AssignmentDurationInSeconds=30 * one_minute,
    Reward='1.00',
    Title='Long Tweet Emotions',
    Keywords='tweet,language,emotion,nctu,nlp,NCTU,NLP,TWEET,NCTU_Team_London',
    Description='Decide how a tweet feels (May include offensive content)',
    QualificationRequirements=[
        {
            'QualificationTypeId': '00000000000000000071', # see https://docs.aws.amazon.com/AWSMechTurk/latest/AWSMturkAPI/ApiReference_QualificationRequirementDataStructureArticle.html#ApiReference_QualificationType-IDs
            'Comparator': 'In',
            'LocaleValues': [
                {
                    'Country': 'TW'
                },
                {
                    'Country': 'US'
                },
            ],
            'RequiredToPreview': True,
            'ActionsGuarded': 'PreviewAndAccept'
        },{'QualificationTypeId':'32X4OLFWW4UYZYT0ET6G5H3L9UETDG',
                                   'Comparator': 'EqualTo',
                                   'IntegerValues':[1]},
    ]
)
"""

#hit_type_id = hit_type_response['HITTypeId']
#hit_type_id1 = hit_type_response1['HITTypeId']
#print(hit_type_id)

"""df = pd.read_csv("./lab4-data.csv") 
title = df.idx.to_list()
corpus = df.text.to_list()
for i in range(377):
  question=f'''<?xml version="1.0" encoding="UTF-8"?>
  <ExternalQuestion xmlns="http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2006-07-14/ExternalQuestion.xsd">
    <ExternalURL>https://allen91239.github.io/hit{i}.html</ExternalURL>
    <FrameHeight>800</FrameHeight>
  </ExternalQuestion>'''

  data = corpus[i]
  wordcount = data.split(' ')
  count = int(len(wordcount))
  if count<31:
    response = client.create_hit_with_hit_type(
        HITTypeId=hit_type_id,
        MaxAssignments=3,
        LifetimeInSeconds=56 * one_day,
        Question=question,
        RequesterAnnotation='tweet',
    )
  else:
    response = client.create_hit_with_hit_type(
        HITTypeId=hit_type_id1,
        MaxAssignments=3,
        LifetimeInSeconds=56 * one_day,
        Question=question,
        RequesterAnnotation='tweet',
    )

#Fetch results
"""

# list_hits_response = client.list_hits()
# hit_id = list_hits_response['HITs'][0]
# response = client.list_assignments_for_hit(HITId=hit_id)

hits_paginator = client.get_paginator('list_hits')
assignments_paginator = client.get_paginator('list_assignments_for_hit')
output = defaultdict(lambda: defaultdict(lambda: 0))
us = pytz.timezone('Asia/Taipei')
setdate = datetime.strptime('2020-05-27 01:00', '%Y-%m-%d %H:%M').replace(tzinfo=us)
#setdate = datetime(2020, 5, 27, 0, 0)
count = 0
for hits in hits_paginator.paginate():
    for hit in hits['HITs']:
        for assignments in assignments_paginator.paginate(HITId=hit['HITId']):
            for assignment in assignments['Assignments']:
              if assignment['SubmitTime'] > setdate:
                print(assignment['SubmitTime'])
                print(setdate)
                print(f"doing work...#{count}")
                count = count + 1
                #print(assignment['Answer'])
                str = assignment['Answer']
                extract_number = re.findall(r'\d+', str) 
                print(extract_number)
                #print(extract_number[5])
                #print(extract_number[6])
                #print(extract_number[7])
                #print(extract_number[8])
                #print(assignment['AcceptTime'])
                #print(assignment['SubmitTime'])
                output[extract_number[5]]['v'] += int(extract_number[6])
                output[extract_number[5]]['a'] += int(extract_number[7])
                output[extract_number[5]]['d'] += int(extract_number[8])
                output[extract_number[5]]['assignment'] += 1
                if output[extract_number[5]]['time'] == 0:
                  output[extract_number[5]]['time'] = (assignment['SubmitTime'] - assignment['AcceptTime']).total_seconds()
                else:
                  output[extract_number[5]]['time'] += (assignment['SubmitTime'] - assignment['AcceptTime']).total_seconds()
                #print((assignment['SubmitTime'] - assignment['AcceptTime']))
                time.sleep(1)

#print(output)
#for idxs in output:
#  print(output[idxs]['v']/output[idxs]['assignment'])
#  print(output[idxs]['a']/output[idxs]['assignment'])
#  print(output[idxs]['d']/output[idxs]['assignment'])
#  print(output[idxs]['time']/output[idxs]['assignment'])

"""#Write to CSV"""

with open('results.csv', 'w', newline='') as csvfile:
  # 定義欄位
  fieldnames = ['idx', 'average_valence', 'average_arousal', 'average_dominance', 'average_time', 'assignments']

  # 將 dictionary 寫入 CSV 檔
  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

  # 寫入第一列的欄位名稱
  writer.writeheader()

  for idx in output:
    writer.writerow({'idx': idx, 'average_valence': output[idx]['v']/output[idx]['assignment'], 'average_arousal': output[idx]['a']/output[idx]['assignment'], 'average_dominance': output[idx]['d']/output[idx]['assignment'], 'average_time': output[idx]['time']/output[idx]['assignment'], 'assignments': output[idx]['assignment']})
csvfile.close()